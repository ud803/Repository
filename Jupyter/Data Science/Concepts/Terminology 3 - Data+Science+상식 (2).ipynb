{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pattern Recognition**은 머신 러닝의 한 분야로서, 패턴의 인식과 데이터의 규칙성에 주목하는 학문이다. (사실 머신 러닝이라는 용어와 거의 유사하게 쓰인다.)\n",
    "\n",
    "Pattern Recognition systems are in many cases trained from labeled \"training\" data (**supervised learning**).\n",
    "<br> But when no labeled data are available, other algorithms can be used to discover previously unknown patterns (**unsupervised learning**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pattern Recognition, Machine Learning, Data Mining, Knowledge discovery in database (KDD)**는 많은 분야에서 겹치기 때문에 구분 짓기가 힘들다.\n",
    "'머신 러닝'은 지도 학습 방법에서 자주 쓰이는 용어이고, 인공지능에서 유래했다.\n",
    "반면, KDD와 데이터 마이닝은 비지도 학습에 더 큰 초점이 있으며 상업적 목적과 연관되어 있다.\n",
    "\n",
    "머신 러닝에서, 패턴 분석은 주어진 입력 값에 라벨을 할당하는 작업이다.\n",
    "통계학에서, 이와 같은 목적을 가진 '판별 분석'이 1936년 소개되었다.\n",
    "\n",
    "패턴 분석의 종류는 다음과 같다.\n",
    "- 'Classification' : 각 입력 값에 주어진 클래스 중 하나를 할당하는 작업이다.\n",
    "- 'Regression' : 각 입력값에 실수 값을 할당해주는 작업이다.\n",
    "- 'Sequence labeling' : 순서가 있는 연속된 값들에 클래스를 할당해주는 작업을 한다. (예를 들어 POS 태깅 같은 경우, 하나의 문장에서 각 단어에 POS를 할당한다.)\n",
    "- 'Parsing' : 입력된 문장에 'Parse Tree'를 할당하여 문장의 구문 구조를 표현한다.\n",
    "\n",
    "패턴 분석은 일반적으로 모든 가능한 입력 값에 대해 합리적이고 \"가장 그럴듯한\" 결과 값을 내놓는 것을 목표로 한다.\n",
    "이는 입력 값에서 주어진 패턴과 정확히 일치하는 것을 찾는 'Pattern Matching'과는 다르다고 할 수 있다. (매칭의 대표적인 예가 Regular Expression 이다.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패턴 분석은 결과 값을 산출해내는 학습 과정에 따라 분류 된다.\n",
    "<br><br>**'Supervised Learning'**은 트레이닝 셋이 제공되어 있고, 그 셋은 정확한 결과값으로 라벨링 되어 있다는 것을 가정한다.\n",
    "그럼 학습 과정은 트레이닝 셋에서도 좋은 성능을 보이고, 새로운 데이터에서도 일반화가 잘되는 언뜻 보면 상충되는 두 개의 목적을 모두 달성하는 'Model'을 만들어낸다.\n",
    "(사실 가장 단순한 모형을 의미한다. 오컴의 면도날 원리와 유사하다)\n",
    "<br><br>**'Unsupervised Learning'**은 반대로 트레이닝 셋이 라벨링 되어있지 않은 상태를 가정한다. 그리고 새로운 데이터에 대해 결과값을 줄 수 있는 데이터 속의 잠재적인 패턴을 찾으려고 노력한다. (이 경우, 트레이닝 셋이 곧 테스트 셋일 수 있다.)\n",
    "<br><br>이 둘의 조합이 **'Semi-supervised Learning'**이고, 라벨링 된 데이터와 그렇지 않은 데이터를 모두 이용한다. (이 경우, 작은 규모의 라벨 데이터와 큰 언라벨 데이터를 함께 사용한다.)\n",
    "\n",
    "<br> *주의할 점은, 앞서 말한 지도 학습과 비지도 학습을 지칭하는 또다른 용어들이 많이 있다는 점이다.\n",
    "예를 들어, 'Unsupervised equivalent of Classification'은 보통 'Clustering'이라고 알려져 있다.*\n",
    "<br><br>**'Clustering'**은 입력 값들을 내재된 '유사도 측정 방식'에 의해서 클러스터로 그룹 짓는 방법이다. 그리고 여기에 사전에 정의된 클래스는 따로 존재하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Terminology\n",
    "\n",
    "결과 값이 산출되는 입력 값의 한 조각을 **'Instance'**라고 부른다.\n",
    "\n",
    "'Instance'는 보통 **'vector of features'**로 표현된다.\n",
    "이 feature 벡터가 모여 instance의 모든 특성을 설명하는 것이다.\n",
    "\n",
    "이 Feature Vector는 '다차원 공간'에서 의 한 점으로서 표현될 수 있고, '벡터 공간'에서 벡터를 조작하는 방법들은 똑같이 이 Feature Vector에도 적용될 수 있다.\n",
    "\n",
    "일반적으로, Feature는\n",
    "<br>**1) Categorical** (혹은 Nominal, e.g., male, female) 데이터 이거나, \n",
    "<br>**2) Ordinal** (e.g., large, medium, small) 이거나, \n",
    "<br>**3) Real-Value** (e.g., measurement of blood pressure)일 수 있다.  \n",
    "\n",
    "일반적으로는 Category와 Ordinal을 함께 묶고, Integer와 Real value를 함께 묶는다.\n",
    "\n",
    "*많은 알고리즘이 오직 Categorical Data에서만 작동하고, 실수형 데이터들이 그룹으로 묶이는 것을 요구한다. (e.g., 5이하, 5초과 10미만, 10이상)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Classifiers\n",
    "\n",
    "많은 패턴 분석 알고리즘은 본질적으로 **'probabilistic'**하다. 왜냐하면 주어진 인스턴스에 대해 최선의 라벨을 산출하기 위해 통계적 추론을 사용하기 때문이다.\n",
    "\n",
    "단순하게 \"최선의\" 라벨만을 내놓는 다른 알고리즘들과 달리, 확률 알고리즘들은 해당 인스턴스가 해당 라벨일 '확률'도 산출해 낸다.\n",
    "\n",
    "게다가, 많은 확률 알고리즘들은 'N개의 최선의 라벨' 목록을 그 확률과 함께 보여주기도 한다.\n",
    "\n",
    "확률 알고리즘은 비확률 알고리즘에 비해 장점이 많다.\n",
    "- 산출값과 관련된 'Confidence Value'를 산출해낸다. (비확률 알고리즘도 이를 산출해낼 수 있지만, 일반적으로 확률 알고리즘만이 확률 이론에 수학적인 근거를 두고 있다.)\n",
    "- 따라서, 해당 값의 'Confidence' 값이 너무 낮다면 그 결과를 지양할 수 있다.\n",
    "- 확률론적 결과값 때문에, 확률 패턴 분석 알고리즘은 더 큰 머신 러닝 기법에 사용될 수 있다. (**'Error Propagation'**을 부분적으로, 혹은 전반적으로 무시할 수 있다.)\n",
    "\n",
    "\n",
    "### Number of important feature variables\n",
    "**'Feature Selection'** 알고리즘은 불필요하거나 관계가 없는 feature를 잘라내는 데 그 목적이 있다.\n",
    "*'Feature Selection'*의 복잡함은 *n 개의 feature가 주어졌을 때, $2^n - 1$ 개 만큼의 Feature의 부분집합을 탐색해야 한다는 'Optimization Problem'에 있다.*\n",
    "\n",
    "**'Branch-and-Bound'** 알고리즘이 이러한 복잡도를 줄여 주긴 하지만, 어느 정도 큰 숫자의 feature에는 적용하기 어렵다는 문제가 있다.\n",
    "\n",
    "**'Feature Extraction'**은 Feature Vector를 변형시키는 작업이다. 종종 패턴 매칭 알고리즘을 적용하기 전에 사용된다.\n",
    "예를 들어, 'feature extraction' 알고리즘은 고차원의 feature vector를 낮은 차원으로 바꿔 작업을 용이하게 하고 불필요한 데이터를 'encode'할 필요가 적어진다.\n",
    "\n",
    "대표적인 수학적 기법으로는 **'Principal Components Analysis(PCA)'**가 있다.\n",
    "\n",
    "Feature Selection과 Extraction의 차이는, Extraction 이후의 Feature는 기존의 Feature와 다른 종류이고, 쉽게 해석하기 힘들 수 있다는 점이다. 이와 반대로 Selection 이후의 Feature는 단순히 원래 집합의 부분집합일 뿐이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement (Supervised Version)\n",
    "\n",
    "일반적으로, 지도 패턴 인식은 다음의 순서대로 이루어진다.\n",
    "1. 미지의 함수 $g : \\mathrm{X} \\to \\mathrm{Y}$ 가 주어진다. 이 때, g는 입력 값 $ x \\in \\mathrm{X} $ 를 라벨값 $ y \\in \\mathrm{Y} $ 로 매핑시키는 함수이다.\n",
    "2. Training Data $ \\mathrm{D} = \\{(x_1,y_1),...,(x_n,y_n)\\}$는 g에 들어가 있다.\n",
    "3. 함수 g와 최대한 비슷한 결과를 내는 함수 $ h : \\mathrm{X} \\to \\mathrm{Y}$ 를 만들어 낸다.\n",
    "4. 여기서 '최대한 비슷한 결과'를 내는 것은 **'Loss Function', 'Cost Function'**의 선택을 통해 정의된다.\n",
    "5. 이 함수들은 잘못된 라벨의 결과로서 나오는 손실에 특정 값을 부여한다. 여기서 목적은 'Expected Loss'를 최소화하는 것이다.\n",
    "6. 손실 함수는 예측되는 라벨의 종류에 따라 달라지는데, 예를 들어 Classification의 경우, 간단한 **'Zero-one loss function'**이 알맞다.\n",
    "7. \n",
    "    1. 여기서 Expectation은 $\\mathrm{X}$의 확률 분포에서 기대값을 구하는 것이다.\n",
    "    2. 확률적 패턴 인식에서는, 이 기대값 대신에 가능한 라벨의 확률을 구한다.\n",
    "<br><br>$$ p(label | x, \\theta) = f(x;\\theta) $$<br>\n",
    "여기서 x는 Feature Vector이고, 함수 f는 보통 파라미터 $\\theta$에 의해 결정된다.\n",
    "\n",
    "        1. **'Discriminative Approach'**에서, f는 직접적으로 추정된다.\n",
    "        2. **'Generative Approach'**에서, $p(x|label)$ 이 추정되고, Prior Prob인 $p(label|\\theta)$와 함께 베이즈 정리를 이용한다.\n",
    "<br><br> $$ p(label | x, \\theta) = \\frac{p(x|label,\\theta)p(label|\\theta)}{\\sum_{L\\in{all,labels}}p(x|L)p(L|\\theta)} $$\n",
    "\n",
    "이 때, $\\theta$의 값은 **'maximum a posteriori (MAP)'**을 이용하여 계산된다.\n",
    "베이지안의 관점에서 보면, 정규화 과정은 Prior Prob인 $\\theta$를 서로 다른 값으로 바꿔주는 과정이라고 할 수 있다.\n",
    "\n",
    "수학적으로,\n",
    "$$ \\theta^{*} = argmax_\\theta p(\\theta|D) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Frequentist or Bayesian approach?\n",
    "피셔가 소개한 최초의 패턴 분석 알고리즘인 \"Linear Discriminant\"는 빈도론에서 탄생하였다. 빈도론자의 접근은 모형의 파라미터가 알려져있지 않지만, 객관적이라고 말한다. 따라서 파라미터는 수집된 데이터로부터 계산된다.\n",
    "\n",
    "베이즈 통계는 고대 그리스 철학에 그 기원이 있다. 그 당시부터 'a priori'와 'a posteriori' 사이에 구분이 있었다. 그 후, 칸트 또한 그 경계를 구분하였다. 베이지안 패턴 분석에서, 클래스의 확률은 사용자에 의해 정해질 수 있다. (이는 a priori이다) 그리고 이러한 베이지안 접근은 전문가의 견해를 주관적인 확률로서 깔끔하게 조화를 이룬다는 사실에 있다.\n",
    "\n",
    "확률론적 패턴 분석은 빈도론자 관점이나 베이지안의 관점에서 사용될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "\n",
    "1. Classification Algorithms (supervised algo predicting categorical labels)\n",
    "    1. Parametric \n",
    "        1. Linear Discriminant Analysis\n",
    "        2. Quadratic Discriminant Analysis\n",
    "        3. Maximum entrophy Classifier (logistic regression)\n",
    "    2. Nonparametric\n",
    "        1. Decision Trees, Decision Lists\n",
    "        2. Kernel Estimation, KNN algo\n",
    "        3. Naive Bayes Classifier\n",
    "        4. Neural Networks (multi-layer perceptrons)\n",
    "        5. Perceptrons\n",
    "        6. Support Vector Machine\n",
    "        7. Gene Expression Programming\n",
    "2. Clustering Algorithms (unsupervised algo predicting categorical labels)\n",
    "    1. Categorical mixture models\n",
    "    2. Deep Learning Methods\n",
    "    3. Hierarchical Clustering\n",
    "    4. K-means Clustering\n",
    "    5. Correlation Clustering\n",
    "    6. Kernel Principal Component Analysis (Kernel PCA)\n",
    "3. Ensemble Learning Algorithms (supervised meta-algorithms for combining mtp learning algo together)\n",
    "    1. Boosting (meta-algorithm)\n",
    "    2. Bootstrap Aggregating(\"bagging\")\n",
    "    3. Ensemble Averaging\n",
    "    4. Mixture of experts, hierarchical mixture of experts\n",
    "4. General Algo for predicting arbitrarily-structured labels\n",
    "    1. Bayesian Networks\n",
    "    2. Markov Random Fields\n",
    "5. Real-valued sequence labeling Algorithms (predicting sequences of real-valued labels)\n",
    "    1. Kalman filters\n",
    "    2. Particle filters\n",
    "6. Sequence labeling algo (predicting sequences of categorical labels)\n",
    "    1. Supervised\n",
    "        1. Conditional random fields (CRFs)\n",
    "        2. Hidden Markov models (HMMs)\n",
    "        3  Maximum entropy Markov models (MEMMs)\n",
    "        4. Recurrent Neural Networks\n",
    "    2. Unsupervised\n",
    "        1. Hidden Markov Models (HMMs)\n",
    "7. Regression Algorithms (predicting real-valued labels)\n",
    "    1. Supervised\n",
    "        1. Gaussian process regression (kriging)\n",
    "        2. Linear Regression and extensions\n",
    "        3. Neural networks and Deep learning methods\n",
    "    2. Unsupervised\n",
    "        1. Independent Component Analysis (ICA)\n",
    "        2. Principal Component Analysis (PCA)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Learning Theory\n",
    "\n",
    "(Computational) [Learning theory](https://en.wikipedia.org/wiki/Computational_learning_theory)는 인공 지능의 하위 분야이며, 머신 러닝 알고리즘의 디자인과 분석이 주된 분야이다.\n",
    "\n",
    "Computational Learning Theory에서는 시간 복잡도와 학습의 가용성에 대해서도 연구한다.\n",
    "\n",
    "연산의 가능성은 \"[Polynomial Time](https://en.wikipedia.org/wiki/Time_complexity#Polynomial_time)\"내에 가능한 지에 달려있다.\n",
    "    \n",
    "다음 두 가지의 시간 복잡도 결과가 있다.\n",
    "    - Positive Result : Polynomial Time 내에 특정 함수가 실행 가능할 경우\n",
    "    - Negative Result : 불가능할 경우\n",
    "        - Negative Result는 보통 옳다고 받아들여지지만, 증명되지는 않은 가정을 따른다\n",
    "            - Computational Complexity - P versus NP problem\n",
    "            - Cryptographic - One-way functions exist\n",
    "Learning Theory에는 또 다른 여러 접근들이 있다. 이들의 차이점은 제한된 데이터로부터 일반화 할 때 추론하는 원칙에 있다.\n",
    "이 때, 확률에 대한 서로 다른 정의, 샘플의 제너레이션에서의 서로 다른 가정들이 포함된다.\n",
    "    - Exact learning (proposed by Dana Angluin)\n",
    "    - Probably Approximately Correct Learning (PAC learning)\n",
    "        - It inspired boosting\n",
    "    - VC Theory\n",
    "        - It led to support vector machine\n",
    "    - Bayesian Inference\n",
    "        - It led to Belief Networks\n",
    "    - Algorithmic Learning Theory\n",
    "    - Online Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagation of uncertainty\n",
    "\n",
    "통계학에서, 'Propagation of Uncertainty'는 '변수의 불확실성'이 '함수의 불확실성'에 영향을 미치는 것을 의미한다.\n",
    "변수들이 실험 측정의 값들일 경우, 그 변수들은 측정의 한계로 인해 불확실성을 가지고 있다. 그리고 그 불확실성은 함수에서 변수의 결합에까지 퍼져나간다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "## Overall\n",
    "**Feature Selection은 Variable S-, Attribute S-, Variable Subset S- 으로도 알려져 있다. **\n",
    "이는 모형을 만드는 데 사용할 feature (or equivalently, variables, predictors)의 부분집합을 선택하는 과정이다.\n",
    "\n",
    "Feature Selection은 크게 4가지 이유로 사용된다.\n",
    "- 모형의 단순화를 통해 사용자들의 해석을 더 용이하게 만든다.\n",
    "- 트레이닝 시간이 줄어든다.\n",
    "- 차원의 저주를 피하기 위해서.\n",
    "- 오버피팅을 줄여서 일반화를 용이하게 한다. (혹은, **\"reduction of variance\"**)\n",
    "    \n",
    "Feature Selection의 대전제는 '데이터가 중복되거나 무관한 Feature들을 가지고 있고, 정보의 큰 손실 없이 그러한 Feature들이 제거될 수 있다'는 것이다. \n",
    "*Redundancy와 Irrelevancy는 서로 다른 개념이다. 한 예로, 관계가 있는 한 특성은 또다른 관계가 있는 한 특성으로 인해 redundant 해 질 수 있다. *\n",
    "\n",
    "Feature Selection은 Feature Extraction과는 다르다. Extraction은 기존 Feature의 함수로서 새로운 Feature를 만들어내는 작업이다. \n",
    "Feature Selection은 Feature는 많지만 비교적 데이터가 적은 경우 사용된다.\n",
    "\n",
    "Feature Selection이 주로 사용되는 분야는 많은 Feature가 존재하지만, 데이터는 적은 written text와 DNA microarray 데이터 분야이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "### 1. Introduction\n",
    "Feature Selection은 \n",
    "<br>1) 새로운 Feature 부분집합을 검색하는 부분과 \n",
    "<br>2) 서로다른 Feature 부분집합을 평가하는 부분으로 나눌 수 있다.\n",
    "\n",
    "각 부분집합을 평가하는 가장 단순한 알고리즘은 \"**error rate**\"을 최소화하는 것을 찾는 것이다. 하지만 이는 \"exhaustive\"한 방법이고, 작은 집합을 제외하고는 처리하기가 힘들다.\n",
    "\n",
    "따라서 이러한 측정 방법이 알고리즘에 가장 큰 영향을 미치고, 알고리즘을 크게 세 부분으로 분류해준다.\n",
    "\n",
    "1. Wrapper\n",
    "<br>Wrapper는 \"**predictive model**\"을 사용하여 부분집합에 점수를 매긴다. \n",
    "<br>각 새로운 부분집합은 모형을 트레이닝하는 데 사용되고, 그 모형은 'hold-out set'에서 테스트된다. \n",
    "그 셋에서 발생한 error rate는 그 subset의 점수가 된다. \n",
    "<br> Wrapper 방법은 모든 부분집합에 대해 새로운 모형을 트레이닝 하기 때문에, 연산 작업이 매우 많지만 일반적으로 '주어진 모형에 대해' 최고의 성능을 낸다.\n",
    "\n",
    "2. Filter \n",
    "<br>Filter는 error rate이 아닌 \"**proxy measure**\"를 사용한다. 이 방법은 계산이 빠르지만, Feature set의 유용함은 그대로 간직한다. \n",
    "<br>방법으로는 \"**mutual information, pointwise mutual information, pearson product-moment correlation coefficient, inter/intra class distance or the scores of significance tests**\" 등이 있다. \n",
    "<br>Filter는 Wrapper에 비해 연산이 많지는 않지만, *특정 Predictive Model에 맞춰지지 않은 Feature Set을 제공한다.*\n",
    "<br>이러한 성질은 Filter의 Feature 집합이 Wrapper보다 더 일반적이라는 것을 의미한다.  따라서 보통 더 낮은 예측력을 갖는다.\n",
    "<br>하지만 모형에 대한 가정이 없기에 Feature 사이의 관계를 밝히는 데 더 유용하다. \n",
    "<br>일반적으로, Filter는 최고의 부분집합을 보여주기 보다는 Feature들의 순위를 보여준다. \n",
    "<br>그리고 그 cutoff point는 \"**Cross Validation**\"을 통해 정해진다.\n",
    "Filter 방법은 Wrapper 방법을 사용하기 전 전처리 단계에서도 쓰이는데, Wrapper가 더 큰 문제에 쓰일 수 있게 도와준다.\n",
    "\n",
    "3. Embedded Method\n",
    "<br>임베디드 메서드는 \"catch-all group of technique\" 이고, 모형을 설계하는 과정에서 Feature Selection을 실행한다. \n",
    "<br>이 방식의 한 예는 선형 모형을 만드는 \"**LASSO**\" 방법인데, 회귀 계수를 \"**L1 Penalty**\"로서 제약을 주고, 그 중 대다수를 0으로 축소시킨다.\n",
    "<br> 0이 아닌 회귀 계수를 갖는 Feature는 LASSO 알고리즘에 의해 '선택'된다. \n",
    "<br> LASSO의 개량 버전은 \"**Bolasso, Elastic net regularization, FeaLect**\" 등이 있다.\n",
    "<br>또 다른 임베디드 메서드로는 \"**Recursive Feature Elimination**\" 알고리즘이 있는데, SVM과 함께 모형을 세우고 가중치가 낮은 Feature를 제거하는 것을 반복한다.\n",
    "<br> 이 방법들은 계산의 복잡도를 놓고 볼때 Filter와 Wrapper 중간 지점에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Subset Selection\n",
    "Feature의 부분집합을 고르는 과정은 Wrapper, Filter, Embedded 방법으로 분류될 수 있다.\n",
    "<br>Wrapper는 탐색 알고리즘을 사용하여 가능한 Feature 공간을 검색하고, 각 부분집합에 대해 모형을 돌려서 평가를 한다.\n",
    "<br>Wrapper는 계산 비용이 높으며 모형의 오버피팅 가능성이 있다.\n",
    "<br>Filter는 검색 방식은 Wrapper와 비슷하지만, 모형에 대해 평가하는 대신 단ㄷ순한 필터를 사용한다.\n",
    "<br>Embedded는 모형에 내재되어 있고, 그 모형에 국한되어있다.\n",
    "\n",
    "많은 검색 알고리즘이 \"**Greedy Hill Climbing**\"을 사용하는데, 반복적으로 후보 집합을 평가한 뒤, 그 집합에 약간의 변형을 주어 그 이전보다 더 나아졌는지를 평가하는 과정을 반복한다. \n",
    "<br>이 때, 집합을 평가하는 scoring metric이 필요하다.\n",
    "<br>이러한 완전한 탐색(Exhaustive Search)은 비효율적이기 때문에, 사전에 정해놓은 지점까지 가장 높은 점수를 받은 후보 집합이 적당한 Feature Subset으로 결정된다.\n",
    "<br>이 때, 사정에 정해놓은 지점은 알고리즘마다 다르지만 다음과 같은 방법이 있다 : subset score가 기준점을 넘을 때, 프로그램의 허용된 런타임이 초과되었을 때 등..\n",
    "<br> 또 다른 검색 알고리즘으로는 \"**Targeted Projection Pursuit**\"에 기초한 방법이 있는데, 가장 점수가 높은 저차원의 데이터를 찾는 작업이다. 즉, 저차원 공간에 가장 큰 Projection을 갖는 Feature들이 선택된다.\n",
    "\n",
    "- 여러 서치 알고리즘\n",
    "    - Exhausitve\n",
    "    - Best first\n",
    "    - Simulated Annealing\n",
    "    - Genetic Algorithm\n",
    "    - Greedy Forward Selection\n",
    "    - Greedy Backward Elimination\n",
    "    - Particle Swarm Optimization\n",
    "    - Targeted Projection Pursuit\n",
    "    - Scatter Search\n",
    "    - Variable Neighborhood Search\n",
    "    \n",
    "- 필터 메트릭\n",
    "<br>Classification에서 사용되는 가장 유명한 필터 두 가지는 \"**Correlation**\"과 \"**Mutual Information**\"이다. 하지만 이 둘 모두 실제 측정기준(metric)이라고 할 수 없다, 이들은 삼각부등식을 만족시키지 못하기 때문이다. 따라서 distance라는 개념보다는 score가 더 어울린다.\n",
    "그 외에도 아래와 같은 필터들이 있다.\n",
    "    - Class Separability\n",
    "        - Error Probability\n",
    "        - Inter-class distance\n",
    "        - Probabilistic distance\n",
    "        - Entropy\n",
    "    - Consistency-based feature selection\n",
    "    - Correlation-based feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic\n",
    "\n",
    "단순히 Heuristic이라고 불리는 \"**Heuristic Technique**\"은 문제 해결, 학습, 발견에서 사용되는 어떠한 접근법이라도 해당된다. 이는 최적화 되어있거나 완벽한 방법들은 아니지만, 단기적인 목표를 위해선 충분하다.\n",
    "<br>최적해를 찾는 것이 불가능하거나 실용적이지 않을 때, 휴리스틱은 만족할 만한 결과를 찾는 데 쓰일 수 있다.\n",
    "<br> 휴리스틱의 예로는 \"**a rule of thumb, an educated guess, an intuitive judgment, guesstimate, stereotyping, profiling, common sense**\" 등이 있다. \n",
    "\n",
    "- 그 외 Heuristics\n",
    "    - Anchoring and adjustment\n",
    "    - Availability Heuristic\n",
    "    - Representativeness Heuristic\n",
    "    - Naive Diversificatiion\n",
    "\n",
    "##### - Rule of Thumb\n",
    "정확하거나 매 상황에 맞지는 않지만 광범위하게 쓰일 수 있는 원칙을 의미한다. \n",
    "<br>이론에 근거하기 보다는 경험에 기반하여 얻어진 방법이며, 쉽게 적용할 수 있는 방법을 의미한다.\n",
    "\n",
    "##### - Guesstimate\n",
    "영단어 'guess'와 'estimate'의 'portmanteau (여행용 짐가방, 둘 이상의 혼성어)' 이다. \n",
    "<br>적절한 정보 없이, 추측에 의해 평가하는 것을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Climbing\n",
    "\n",
    "Hill Climbing은 \"**Local Search**\"에 속하는 수학적 최적화 기법이다.\n",
    "<br> \"**Iterative Algorithm**\"이며, 임의의 해에서 시작하여 점차적으로 한 가지 원소를 변경하여 더 나은 해를 찾으려는 시도이다.\n",
    "<br> 변경으로 인한 해가 더 좋은 결과를 만들다가, 더 이상 변경할 점이 없게되면 알고리즘은 종료된다.\n",
    "\n",
    "이 방법은 '[Travelling Salesman Problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem)'에 적용될 수 있다. 이 때, 알고리즘은 임의의 한 방법에서 시작하여 순서를 바꾸는 등 조금씩 개선해 나간다.\n",
    "\n",
    "\n",
    "\n",
    "##### - Convex Problem\n",
    "Convex Minimazation은 최적화의 한 분야이며, \"**Convex Set**\"에서 \"**Convex Function**\"을 최소화시키는 문제를 다룬다. \n",
    "\n",
    "Convexity는 최적화 문제를 일반적인 상황보다 더 쉽게 만드는데, 극소값(local minimum)이 최소값(global minimum)이 되고, 이는 최적성에 충분 조건이기 때문이다. \n",
    "\n",
    "Convex Minimization은 여러 학문에서 쓰이고 있다 ; \"automatic control system\", \"signal processing\", \"circuit design\", finance, statistics, structual optimization.\n",
    "\n",
    "** Def **\n",
    "Given a real vector space $ \\mathrm{X}$ together with a convex, real-valued function defined on a convex subset $\\chi$ of $\\mathrm{X}$\n",
    "\n",
    "$$ f : \\chi \\to \\mathrm{R}; \\forall{x_1, x_2} \\in \\chi, \\forall{t} \\in [0, 1] : f(tx_1 + (1-t)x_2) <= tf(x_1) + (1-t)f(x_2) $$\n",
    "\n",
    "여기서 해결하고자 하는 것은 $f(x)$값을 최소화시키는 $\\chi$에 속하는 점 $x$를 찾는 것이다.\n",
    "\n",
    "$$ f(x^*) <= f(x),  \\forall{x}\\in\\chi$$\n",
    "\n",
    "https://en.wikipedia.org/wiki/Mutual_information\n",
    "https://en.wikipedia.org/wiki/Hill_climbing\n",
    "https://en.wikipedia.org/wiki/Local_search_(optimization)\n",
    "https://en.wikipedia.org/wiki/Triangle_inequality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convexity에 대한 정리 필요\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Complexity\n",
    "\n",
    "https://en.wikipedia.org/wiki/Time_complexity#Polynomial_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://en.wikipedia.org/wiki/Branch_and_bound"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Decision_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://en.wikipedia.org/wiki/Statistical_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://en.wikipedia.org/wiki/Curse_of_dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P vs NP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "`\"the Collection and manipulation of items of data to produce meaningful information.\"`\n",
    "\n",
    "Data Processing may involve various processes, including :\n",
    "    - Validation\n",
    "    - Sorting\n",
    "    - Summarization\n",
    "    - Aggregation\n",
    "    - Analysis\n",
    "    - Reporting\n",
    "    - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data\n",
    "\n",
    "`\"Big data is data sets that are so voluminous and complex that traditional data processing application software are inadequate to deal with them.\"`\n",
    "\n",
    "빅데이터가 직면한 과제는 다음과 같다 : **Capturing data, data storgae, data analysis, search, sharing, transfer, visualization, querying, dupating and information privacy.**\n",
    "\n",
    "빅데이터에는 5개의 차원이 있다 : 기존의 3Vs(Volume, Variety, Velocity) + 새로운 2Vs(Veracity, Value)\n",
    "    - Volume : 만들어지고 저장된 데이터의 양\n",
    "    - Variety : 데이터의 종류와 성질\n",
    "    - Velocity : 데이터가 생성되고 가공되는 속도\n",
    "    - Variability : 데이터셋의 변동성은 데이터를 가공하고 조작하는 과정을 망칠 수 있다\n",
    "    - Veracity(정확도) : 얻어진 데이터의 품질은 다양하며, 분석의 품질에 영향을 미친다.\n",
    "    \n",
    "요즘 들어, 빅데이터라는 단어는 예측 분석, 사용자 분석 등 다른 데이터 분석 모형을 의미하게 되었다. (데이터셋의 크기에 집중하기 보다는) \n",
    "\n",
    "요즘 세상에서 데이터의 양이 정말로 'big'하다는 것에는 이견이 없지만, 새로운 데이터 생태게에서 그것은 그렇게 중요하지 않다.\n",
    "\n",
    "데이터셋의 분석은 \"사업 기회를 찾고, 질병을 예방하고, 범죄를 막는 등\" 새로운 연관성을 찾을 수 있다.\n",
    "\n",
    "\"**Relational Database Management System**\"과 기존의 통계, 시각화 소프트웨어는 빅데이터를 다루는 데 적합하지 않다. 빅데이터의 업무는 보통 수십, 수백, 수천개의 서버에서 광범위하게, 동시에 작동할 수 있는 소프트웨어를 필요로 하기 때문이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDBMS\n",
    "Relational Database Management System은 관계형 모형에 기반한 데이터베이스 관리 시스템이다.\n",
    "RDBMS는 1980년대부터 새로운 데이터베이스로 쓰이기 시작했으며, 그 전에 쓰이던 \"**Hierarchical Database**\"와 \"**Network Database**\"를 대체하기 시작했다.\n",
    "\n",
    "하지만 1980년대, 1990년대에 들어 \"**Object DBMS**\"에 도전을 받았다. (RDBMS와 관계지향형 프로그램 사이의 *Object-Relational Impedance Mismatch* 문제를 해결하기 위해 도입됨). 또한 \"**XML DBMS**\"으로부터도 위협을 받았다. 그럼에도 불구하고 RDBMS는 시장에서 권위를 지킨다.\n",
    "\n",
    "### Market Share\n",
    "2017년 5월 기준, 가장 널리 사용되는 RDBMS는 Oracle과 MySQL(오픈소스), Microsoft SQL Server, PostgreSQL (오픈소스), IBM DB2, Microsoft Access, SQLite (오픈소스) 이다. \n",
    "\n",
    "상업적 5대 기업은 오라클 ,IBM, Microsoft, SAP, Teradata 이다.\n",
    "\n",
    "\n",
    "### Relational Model\n",
    "관계형 모형은 \n",
    "https://en.wikipedia.org/wiki/Relational_model\n",
    "https://en.wikipedia.org/wiki/Object_database\n",
    "\n",
    "\n",
    "\n",
    "- First-order Logic (First-order predicate logic)\n",
    "\n",
    "\n",
    "- Hierarchical Database Model\n",
    "데이터가 트리의 형태로 저장되어 있는 데이터 모형이다. 데이터는 **record** 형태로 저장되며, 다른 데이터와 **link**를 통해 연결되어 있다. \n",
    "*Record*는 필드의 집합이며, 각 필드는 오직 하나의 값을 가진다.\n",
    "레코드의 **Entity Type**은 레코드가 어떤 필드를 갖는 지 결정한다. 계층 모형에서 레코드는 관계형 모형에서의 행(tuple)에 대응되고, entity type은 table (relation)에 해당된다.\n",
    "\n",
    "계층 모형에서 각 자식 레코드는 오직 하나의 부모 레코드를 갖고, 부모 레코드는 여러 자식 레코드를 가질 수 있다.\n",
    "\n",
    "계층 모형에서 데이터에 접근하려면, Root부터 시작하여 전체 트리를 경유해야 한다. 1960년대에 IBM에 의해 만들어진 최초의 데이터베이스 모형이다.\n",
    "\n",
    "\n",
    "- Network Database Model\n",
    "네트워크 모형은 오브젝트와 그 관계를 유연하게 나타내는 데이터베이스 모형이다. \n",
    "가장 큰 특징은 스키마(**Schema**)를 그래프로 표현했을 때, 계층이나 격자형 모형에 제한되지 않는다는 점이다.\n",
    "\n",
    "계층 모형이 데이터를 레코드의 트리로 구성하는 반면, 네트워크 모형에서 각 레코드는 여러 부모 레코드와 여러 자식 레코드를 가질 수 있다. \n",
    "\n",
    "이 특징은 다음 두 측면에서 효과가 있다\n",
    "    1. 스키마는 Relationship Type으로 연결된 레코드 타입이다.\n",
    "    2. 데이터베이스 자체가 Relationship으로 연결된 Record의 그래프이다.\n",
    "계층 모형에 비해 네트워크 모형이 갖는 장점은 entity 사이의 관계를 더 자연스럽게 모형화 할 수 있었다는 점이다.\n",
    "\n",
    "하지만 두 가지 이유로 주류가 되지 못했는데,\n",
    "    1. IBM이 semi-network extension을 고수했기 때문이다.\n",
    "    2. 결국 관계형 모형에 의해 대체되었기 때문이다.\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics\n",
    "\n",
    "**예측 분석(Predictive Analytics)**은 예측 모델링(Predictive Modeling), 머신 러닝, 데이터 마이닝 등 넓은 통계적 기법을 널리 포함하는 개념이며 현재와 과거의 데이터를 이용하여 미래나 알려지지 않은 사건에 대한 예측을 하는 기법이다.\n",
    "\n",
    "예를 들어, 기업에서는 과거 데이터에서 발견된 패턴을 이용하여 위험과 기회를 발견한다. 이 때 사용되는 예측 모형은 많은 요소간의 관계를 분석하여 특정 상황에서의 위험도를 평가하여 의사 결정에 도움을 준다.\n",
    "\n",
    "예측 분석의 핵심은 설명 변수와 반응 변수 사이의 관계를 캐치하여 미지의 결과를 예측하는 데 사용하는 것이다.\n",
    "\n",
    "### 예측 분석 프로세스\n",
    "    - 프로젝트 정의\n",
    "    - 데이터 수집\n",
    "    - 데이터 분석 : 데이터 관측, 클리닝, 모델링을 통해 유용한 정보를 얻어내고 결론을 이끌어 낸다\n",
    "    - 통계적 분석 : 가정, 가설을 검정하고 표준 통계 모형을 통해 검증한다.\n",
    "    - 모델링\n",
    "    - 모델 적용\n",
    "    - 모델 검증\n",
    "\n",
    "\n",
    "### 예측 분석의 응용\n",
    "- Analytical CRM\n",
    "- Child Protection\n",
    "- Clinical Decision support system\n",
    "- Collection Analytics\n",
    "- Cross-sell\n",
    "- Customer Retention\n",
    "- Fraud Detection\n",
    "\n",
    "### 예측 분석의 종류(?)\n",
    "일반적으로, \"예측 분석\"이라는 용어는 예측 모형, 데이터에 값을 매기는 행위, 그리고 예측(Forecasting)을 의미한다. \n",
    "하지만 점점 사람들은 유사한 분석 학문인 **descriptive model**, **decision model** 혹은 **optimization**과 이를 혼동하고 있다. \n",
    "\n",
    "이 분야들도 데이터 분석이 포함돼 있기는 하지만, 서로 목적이 다르고 그 뒤에 숨겨진 통계적 기법이 조금씩 다르다.\n",
    "\n",
    "- Predictive Model (예측 모형)\n",
    "예측 모형은 표본에서 한 유닛의 특정 결과값과 그 유닛의 하나 이상 알려진 특성 사이의 관계를 나타내는 모형이다. \n",
    "모형의 목표는 다른 표본의 비슷한 유닛이 그러한 결과값을 보여줄 확률을 측정하는 것이다. \n",
    "연산 속도의 발전으로, Individual Agent Modeling System이 인간 행동을 복원해내는 게 가능해졌다.\n",
    "\n",
    "특성과 결과값이 알려져 있는 표본을 \"**Training Sample**\"이라고 부르고, 특성은 알려져 있지만 결과값이 알려져 있지 않은 샘플을 \"**out of training sample**\"이라고 부른다. 이 샘플들은 트레이닝 샘플과 시간적 관계에 있을 필요는 없다. \n",
    "\n",
    "- Descriptive Model (기술 모형)\n",
    "기술 모형은 고객을 분류하는 것처럼 데이터 안의 관계를 정량화한다.\n",
    "단일 고객의 행동 예측에 집중하는 예측 모형과 달리, 기술 모형은 고객 간, 혹은 상품 간 서로 다른 관계들을 찾아낸다.\n",
    "기술 모형은 예측 모형이 하는 것처럼 특정 행동의 가능성에 따라 고객을 순위매기는 대신, 상품 선호나 인생 주기에 따라 고객을 분류하는 일을 한다.\n",
    "\n",
    "기술 모형은 더 큰 경제 주체를 재현하고 예측을 하는 데 쓰일 수 있다.\n",
    "\n",
    "- Decision Model (의사결정 모형)\n",
    "의사결정 모형은 의사결정의 결과를 예측하기 위해 의사결정의 모든 요소들 사이의 관계를 묘사한다. \n",
    "이 모형들은 최적화, 최대화 기법들을 포함한다. \n",
    "의사결정 모형은 일반적으로 고객이나 상황에 따른 적합한 행동을 만들어내기 위해 의사결정 로직과 원칙을 세운다.\n",
    "\n",
    "\n",
    "### Predictive Modeling\n",
    "예측 모형은 결과를 예측하기 위해 통계를 사용한다. 대부분 예측할 사건은 미래에 있지만, 시간에 관계 없이 적용될 수 있다.\n",
    "\n",
    "정의마다 다르지만, 예측 모형은 머신 러닝의 분야와 많이 오버랩된다. \n",
    "\n",
    "- Models\n",
    "거의 모든 회귀 모형은 예측을 위해 쓰일 수 있다. \n",
    "\n",
    "크게 분류하면, \"**Parametric**\"한 방법과 \"**Non-parametric**\"한 방법이 있다. \"Semi-Parametric\"한 모형은 이 둘을 포함한다. \n",
    "\n",
    "모수적 방법은 모집단의 모수의 분포에 대한 가정을 하는 반면, 비모수적 방법은 그에 비해 가정이 덜하다.\n",
    "\n",
    "    - Group method of data handling\n",
    "    - Naive Bayes\n",
    "    - k-nearest neighbor algorithm\n",
    "    - Majority Classifier\n",
    "    - Support Vector Machine\n",
    "    - Random Forests\n",
    "    - Boosted Trees\n",
    "    - CART (Classification and Regression Trees)\n",
    "    - MARS (Multivariate adaptive regression splines)\n",
    "    - Neural Networks\n",
    "    - ACE and AVAS\n",
    "    - Ordinary Least Squares\n",
    "    - Generalized Linear Models (GLM)\n",
    "    - Logistic Regression\n",
    "    - Generalized Additive Models\n",
    "    - Robust Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Predict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanatory model vs Descriptive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prescriptive Analytics\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
